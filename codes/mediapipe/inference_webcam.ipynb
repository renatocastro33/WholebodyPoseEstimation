{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "#module_path = os.path.dirname(os.path.abspath(__file__))\n",
    "#sys.path.insert(1, os.path.join(module_path,'../../src/'))\n",
    "sys.path.insert(1,'../../src/')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from models.mediapipe.model import mediapipe_model\n",
    "from models.mediapipe.map_mp2coco import MP2COCO\n",
    "from rtmlib import Wholebody, draw_skeleton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715170554.234668 1130584 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1715170554.236630 1130642 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1715170554.241702 1130584 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1715170554.242616 1130657 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "I0000 00:00:1715170554.250734 1130584 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1715170554.251792 1130672 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n"
     ]
    }
   ],
   "source": [
    "model = mediapipe_model()\n",
    "maper = MP2COCO()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a video capture object \n",
    "vid = cv2.VideoCapture(2) \n",
    "\n",
    "while(True): \n",
    "    \n",
    "    ret, frame = vid.read() \n",
    "    if ret is None:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = model.predict(frame_rgb)\n",
    "    #frame = model.draw_mediapipe(frame,results)\n",
    "    keypoints, scores = maper.process(frame,results)\n",
    "\n",
    "    frame = draw_skeleton(frame, keypoints, scores, kpt_thr=0.5,\n",
    "                                line_width=3,radius=3)\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('frame', frame) \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign_env3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
